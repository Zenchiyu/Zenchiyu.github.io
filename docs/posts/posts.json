[
  {
    "path": "posts/2023-08-27-pca-principal-component-analysis/",
    "title": "PCA: Principal Component Analysis (Draft)",
    "description": "What is Principal Component Analysis ?",
    "author": [
      {
        "name": "Stéphane Liem Nguyen",
        "url": {}
      }
    ],
    "date": "2023-08-27",
    "categories": [
      "unsupervised learning"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nUnsupervised Learning\r\nDimensionality reduction\r\nEigenvalue Decomposition\r\n\r\nPrincipal Component Analysis\r\nAssumptions\r\nIntuition\r\nRelation with mathematical formulas\r\nEckart-Young Theorem and how many dimensions to keep based on the eigenspectrum ?\r\nConclusion\r\n\r\n\r\nIntroduction\r\nPrincipal Component Analysis for short PCA, is an unsupervised learning method that can be used, depending on specific circumstances, as a dimensionality reduction technique. However, PCA is an exact decomposition method. PCA is the eigenvalue decomposition (EVD) of the data covariance matrix.\r\nIn this article, you will see an explanation of what PCA is, intuitively and slightly formalized using some linear algebra.\r\nUnsupervised Learning\r\nThe field of Machine Learning includes a sub-field called unsupervised learning.\r\nUnsupervised learning methods apply to non-labeled data, e.g. images of cats and dogs deprived of class belonging information. These methods are useable for clustering, density estimation, visualization and dimensionality reduction.\r\nDimensionality reduction\r\nMachine Learning methods can suffer from large dimensions. For instance, images can be composed of millions of pixels.\r\nThe large number of dimensions not only can be a burden in terms of computational resources, but intuition from 2, 3 or maybe up to 4 dimensions is hard to extend to thousands of dimensions.\r\nA keyword often used in Machine Learning is the Curse of Dimensionality, we will go more into it in other articles.\r\n\r\nTherefore, shrinking that number of dimensions require dimensionality reduction techniques. However, loss of information can occur! You can think of it as compressing images and decompressing them. Can you retrieve the original image from a compressed one without any loss? Lossy and lossless compression techniques exist with different compression ratios.\r\nBecause loss of information can occur, we need to ensure that the dimensionality reduction technique retains useful information for a downstream task, which could be classification.\r\n\r\nUsefulness needs a proper definition\r\nNote that we’ve only talked about unsupervised learning but dimensionality reduction techniques also exist for supervised learning methods, methods that are applied to labeled data.\r\n\r\nEigenvalue Decomposition\r\nPrincipal Component Analysis\r\nAssumptions\r\nIntuition\r\nRelation with mathematical formulas\r\nEckart-Young Theorem and how many dimensions to keep based on the eigenspectrum ?\r\nConclusion\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-08-28T20:15:08+02:00",
    "input_file": "pca-principal-component-analysis.knit.md"
  },
  {
    "path": "posts/2023-08-26-who-am-i/",
    "title": "Who Am I",
    "description": "Introduction",
    "author": [
      {
        "name": "Stéphane Liem Nguyen",
        "url": {}
      }
    ],
    "date": "2023-08-26",
    "categories": [
      "intro"
    ],
    "contents": "\r\n\r\nContents\r\nCurrent Day\r\nDay 0\r\n\r\nCurrent Day\r\nI’m Stéphane and I’m a computer science student at University of Geneva.\r\nMy academic interests revolve around Machine Learning, more specifically Reinforcement Learning.\r\nMore generally, I’m interested in anything related to decision-making.\r\nBut what ignited that spark of interest ?\r\nDay 0\r\nArtificial Intelligence used to be a foreign concept to me, outside of my interest radar. However, an event at my high school showcasing different scientific disciplines changed that.\r\nThis is in this event, at Collège Claparède, that I discovered the concept of Neural Networks. It was explained to us as a black box, taking an image of a dog and spitting out the class label saying whether it’s a dog or a cat, which led to some frustration.\r\nWhy did he not explain how to construct that black box ? How to construct it ?\r\nThese questions led to the start of my journey.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-08-27T14:24:49+02:00",
    "input_file": {}
  }
]
